{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import pprint\n",
    "import pandas as pd\n",
    "from jira import JIRA\n",
    "import os\n",
    "import warnings\n",
    "import pg_connect\n",
    "\n",
    "warnings.filterwarnings('ignore', message='Unverified HTTPS request')\n",
    "DOCKER_CONTAINER = os.environ.get('DOCKER_CONTAINER', False)\n",
    "print(f'Docker Container: {DOCKER_CONTAINER}')\n",
    "if not DOCKER_CONTAINER:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "\n",
    "# configuration\n",
    "pd.options.mode.chained_assignment = None\n",
    "# configuration\n",
    "jira_base_url = os.environ.get('JIRA_CLOUD_URL')\n",
    "print(f'Jira URL: {jira_base_url}')\n",
    "\n",
    "DATA_REPT_BASE = 'data'\n",
    "\n",
    "username = os.environ.get('JIRA_USER_LOCAL')\n",
    "pwd = os.environ.get('JIRA_TOKEN_LOCAL')\n",
    "\n",
    "print(f'username: {username}')\n",
    "proxies = {\n",
    "    'http': 'http://proxyuser:proxypass@proxycachest.hewitt.com:3228',\n",
    "    'https': 'http://proxyuser:proxypass@proxycachest.hewitt.com:3228'\n",
    "}\n",
    "\n",
    "os.environ['http_proxy'] = 'http://proxyuser:proxypass@proxycachest.hewitt.com:3228'\n",
    "os.environ['https_proxy'] = 'http://proxyuser:proxypass@proxycachest.hewitt.com:3228'\n",
    "# pretty print configuration\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "jira = JIRA(basic_auth=(username, pwd), options={'server':jira_base_url, 'verify':False}, validate=False, proxies=proxies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "def rgetattr(obj, attr, *args):\n",
    "    def __getattr(obj, attr):\n",
    "        return getattr(obj, attr, *args)\n",
    "    return functools.reduce(__getattr, [obj] + attr.split('.'))\n",
    "\n",
    "def get_field_data(field, name):\n",
    "    return rgetattr(field, name, 'Not Populated')\n",
    "\n",
    "def get_type(input_val):\n",
    "    if input_val:\n",
    "        if 'None' in input_val:\n",
    "            return 'None'\n",
    "        if 'Yes' in input_val:\n",
    "            return 'Yes'\n",
    "        if 'No' in input_val:\n",
    "            return 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jql = 'project = ADAMIGR AND issuetype = Epic AND status = Open ORDER BY createdDate'\n",
    "proj_issues = []\n",
    "\n",
    "print('Extracting epics...')\n",
    "for issue in jira.search_issues(jql, maxResults=50):\n",
    "    # issue_list = issue.fields()\n",
    "    # print(*issue_list, sep=\"\\n\")\n",
    "\n",
    "\n",
    "    issue_func_dict = {\n",
    "        'key': issue.key,\n",
    "        'issue_id': issue.id,\n",
    "        'project': issue.fields.project.name,\n",
    "        'status': issue.fields.status.name,\n",
    "        'issue_type': issue.fields.issuetype.name,\n",
    "        'create_date': issue.fields.created,\n",
    "        'update_date': issue.fields.updated,\n",
    "        'summary': issue.fields.summary\n",
    "    }\n",
    "    # print('{}: {}'.format(issue.key, issue.fields.summary))\n",
    "    issue_list = {}\n",
    "    for key in issue_func_dict:\n",
    "        f = issue_func_dict.get(key)\n",
    "        res = f\n",
    "        issue_list[key] = str(res)\n",
    "\n",
    "        # print(f'result: {res}')\n",
    "    proj_issues.append(issue_list)\n",
    "\n",
    "print('All Migration Ticket Extraction complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_proj = pd.DataFrame.from_dict(proj_issues)\n",
    "df_proj = df_proj[df_proj['issue_type'] == 'Epic']\n",
    "df_proj[\"create_date\"] = pd.to_datetime(\n",
    "    df_proj[\"create_date\"], format=\"%Y-%m-%d\")\n",
    "df_proj[\"update_date\"] = pd.to_datetime(\n",
    "    df_proj[\"update_date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "# df_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting issues from tickets\n",
    "\n",
    "epic_link_list = df_proj['key'].tolist()\n",
    "pp.pprint(epic_link_list)\n",
    "\n",
    "epic_link_issues = []\n",
    "validation_issues = []\n",
    "print('Extracting issues...')\n",
    "for epic_link in epic_link_list:\n",
    "    jql = '\"Epic Link\"=' + epic_link\n",
    "    for issue in jira.search_issues(jql, maxResults=50):\n",
    "        issue_func_dict = {\n",
    "            'key': get_field_data(issue, 'key'),\n",
    "            'issue_id': get_field_data(issue, 'id'),\n",
    "            'issue_parent_ticket': get_field_data(issue, 'fields.parent.key'),\n",
    "            'issue_parent_ticket_summary': get_field_data(issue, 'fields.parent.fields.summary'),\n",
    "            'issue_rest_url': get_field_data(issue, 'self'), #issue.self,\n",
    "            'assignee': get_field_data(issue, 'fields.assignee.displayName'), #issue.fields.assignee.displayName,\n",
    "            'reporter': get_field_data(issue, 'fields.reporter.displayName'), #issue.fields.reporter.displayName,\n",
    "            'status': get_field_data(issue, 'fields.status.name'), #issue.fields.status.name,\n",
    "            'issue_type': get_field_data(issue, 'fields.issuetype.name'), #issue.fields.issuetype.name,\n",
    "            'resolution_description': get_field_data(issue, 'fields.status.description'), #issue.fields.status.description,\n",
    "            'create_date': get_field_data(issue, 'fields.created'), #issue.fields.created,\n",
    "            'update_date': get_field_data(issue, 'fields.updated'), #issue.fields.updated,\n",
    "            'summary': get_field_data(issue, 'fields.summary'), #issue.fields.summary,\n",
    "            'description': get_field_data(issue, 'fields.description'), #issue.fields.description\n",
    "            'service_name': get_field_data(issue, 'fields.customfield_10320'), \n",
    "            'mig_req_url': get_field_data(issue, 'fields.customfield_10321'), \n",
    "            'dev_approved_by': get_field_data(issue, 'fields.customfield_10251'), \n",
    "            'qa_test_approved_by': get_field_data(issue, 'fields.customfield_10252'), \n",
    "            'int_test_approved_by': get_field_data(issue, 'fields.customfield_10327'), \n",
    "            'dev_approved': get_field_data(issue, 'fields.customfield_10234'),\n",
    "            'new_docker_secrets': get_field_data(issue, 'fields.customfield_10325.value'),\n",
    "            'qa_test_script_approved': get_field_data(issue, 'fields.customfield_10237'), \n",
    "            'ace_migration_status': get_field_data(issue, 'fields.customfield_10238.value'),\n",
    "            'migration_approved_by': get_field_data(issue, 'fields.customfield_10252.displayName.value'),  \n",
    "\n",
    "            \n",
    "        }\n",
    "        issue_list = {}\n",
    "        for key in issue_func_dict:\n",
    "            f = issue_func_dict.get(key)\n",
    "            res = f\n",
    "            issue_list[key] = str(res)\n",
    "        epic_link_issues.append(issue_list)\n",
    "\n",
    "print('Epic Link Issue Extraction complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dataframe\n",
    "\n",
    "df = pd.DataFrame.from_dict(epic_link_issues)\n",
    "df = df[df['issue_type'] == 'Migration Request']\n",
    "df['create_date'] = pd.to_datetime(df['create_date'], utc=True)\n",
    "df[\"update_date\"] = pd.to_datetime(df[\"update_date\"], utc=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply lambda\n",
    "\n",
    "df['dev_approved'] = df.apply(lambda row: get_type(row['dev_approved']), axis=1)\n",
    "df['qa_test_script_approved'] = df.apply(lambda row: get_type(row['qa_test_script_approved']), axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset of dataframe for Ready for QA Migration\n",
    "df_qa = df[df['ace_migration_status'] == 'Ready for QA migration']\n",
    "# df_qa\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional functionality\n",
    "# qa_test_approved_by\tint_test_approved_by\tdev_approved\tqa_test_script_approved\tace_migration_status\tmigration_approved_by\n",
    "\n",
    "def validate_ticket(df_row, lifecycle='qa'):\n",
    "    # if 'None' in df_row[\"qa_test_approved_by\"]:\n",
    "    #     return False\n",
    "    if 'None' in df_row[\"int_test_approved_by\"]:\n",
    "        return False\n",
    "    if 'None' in df_row[\"dev_approved_by\"]:\n",
    "        return False\n",
    "    if 'None' in df_row[\"dev_approved\"]:\n",
    "        return False\n",
    "    if lifecycle == 'qc':\n",
    "        if 'None' in df_row[\"qa_test_script_approved\"]:\n",
    "            return False        \n",
    "        if 'Not Populated' in df_row[\"migration_approved_by\"]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "df_qa['valid_ticket'] = df_qa.apply(lambda row: validate_ticket(row, lifecycle='qc'), axis=1)\n",
    "\n",
    "\n",
    "df_qa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_qc = df[df['ace_migration_status'] == 'Not Populated']\n",
    "df_qc['valid_ticket'] = df_qc.apply(lambda row: validate_ticket(row,'qc'), axis=1)\n",
    "df_qc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to db\n",
    "pg_table_name = 'ada_migr_ticket_validation_int_cloud'\n",
    "try:\n",
    "    results = pg_connect.write_to_pg_database(pg_table_name, df_qa)\n",
    "    print(results)\n",
    "except (Exception) as e:\n",
    "    print(f'An exception occurred: {e}')\n",
    "print('Migration Ticket data written to database')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f94a3a0e26d021105729bdb87fd473d1d03620362de517711db3662d633d1f92"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
